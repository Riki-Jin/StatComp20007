---
title: "Homeworks"
author: "Zhang Jin 20007"
date: "2020/12/18"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Homeworks for Statistics Computing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=6, fig.height=6) 
```

# Assert

In order to shorten the compile time of the vignette, I reduce the sample size or forbid running of several exercises comparing with my assignment submitted. To be specific, the difference will be listed down below:  

Reduction of sample size:  

1. Homework 5, Exercise 6.C, I reduce the two sample sizes 1000 and 100 respectively to 100 and 30.

Forbiddance of running:  

1. Homework 7, Discussion

2. Homework 8, Gelman-Rubin method.

# Homework 1 (2020-09-22)

## Question

Use knitr to produce 3 examples in the book. The 1st example should contain texts and at least one figure. The 2nd example should contains texts and at least one table. The 3rd example should contain at least a couple of LaTeX formulas.

## Answer

### (1)
In my first example, I used lattice package to make density plot. For the randomly generated data, I plotted both empirical density curve and normal fitting curve.

```{r}
library(lattice)
n <- seq(5, 45, 5)
x <- rnorm(sum(n))
y <- factor(rep(n, n), labels=paste("n =", n))
densityplot(~ x | y,
panel = function(x, ...) {
panel.densityplot(x, col="DarkOliveGreen", ...)
panel.mathdensity(dmath=dnorm,
args=list(mean=mean(x), sd=sd(x)),
col="darkblue")
})

```

### (2)
In my second example, I used some methods to deal with the longitudinal data of some patients.


```{r}
stdv = function(x) {  if (NROW(x)>1)   sigma <- round(sd(x),2) 
                                   else   sigma <- 0
                                   sigma }
smry <- function(X){     mu <- apply(X,2,mean)  
sigma <- apply(X,2,stdv)
c(mu=mu,sigma=sigma)}

patients <- c("0071021198307012008001400400150",
                       "0071201198307213009002000500200",
                      "0090903198306611007013700300000",
                      "0050705198307414008201300900000",
                     "0050115198208018009601402001500",
                     "0050618198207017008401400800400",
                     "0050703198306414008401400800200")
id <- substr(patients,1,3)    # First 3 digits signify the patient ID
date <- as.Date(substr(patients,4,11), format = "%m%d%Y")    # 4-11 for treatment date
hr <- as.numeric(substr(patients,12,14))    # Heart rate
sbp <- as.numeric(substr(patients,15,17))    # Systolic blood pressure
dbp <- as.numeric(substr(patients,18,20))    # Diastolic blood pressure
dx <- substr(patients,21,23)
docfee <- as.numeric(substr(patients,24,27))  
labfee <- as.numeric(substr(patients,28,31))

tapply(hr, id, mean)
tapply(hr, id, stdv)

# Show these results in a more compact way
PATIENTS <- data.frame(id, hr, sbp, dbp, docfee, labfee)
str(PATIENTS)
smry(PATIENTS[id=='005',2:6])
smry(PATIENTS[id=='007',2:6])
smry(PATIENTS[id=='009',2:6])
by(PATIENTS[2:6], id, smry) 
by(PATIENTS[2:6], id, summary)

# Calculate the difference between the first and the last observations of HR, SBP and DBP
HrSbpDbp  <- data.frame(id, date, hr, sbp, dbp)
# Sort by ID first, then sort by treatment date
HrSbpDbpSorted <- HrSbpDbp[order(HrSbpDbp$id, HrSbpDbp$date), ] 
HrSbpDbpSorted
```

### (3)
In this example, I listed several theorems using some Latex copulas.  

Levy CLT:  

$\displaystyle\frac{\sqrt{n}(\bar{X} - \mu)}{\sigma} \stackrel{d}{\longrightarrow} N(0,1)$  
  
Berry-Esseen CLT:  
  
$\displaystyle\sup_{t} |G_n(t)-\Phi(t)| \leq C \frac{\rho}{\sigma^3 \sqrt{n}}$  
  
Percentile CLT:  

$\displaystyle\lim_{n \rightarrow \infty} P \Big( \frac{\sqrt{n} (\hat{\xi}_{pn}-\xi_p)}{\sqrt{p(1-p)}/F'(\xi_p -)} \leq t \Big) = \Phi(t)$  

$~$  

$~$

# Homework 2 (2020-09-29)

## Exercise 3.3
### Problem
The Pareto(a, b) distribution has cdf   

$$\displaystyle F(x)=1-(\frac{b}{x})^a,~~~~~~~x \geq b >0,~a>0.$$  

Derive the probability inverse transformation $F^{-1}(U)$ and use the inverse transform method to simulate a random sample from the Pareto(2,2) distribution. Graph the density histogram of the sample with the Pareto(2,2) density superimposed for comparison.




### Solution

First, for the cdf  

$$\displaystyle F(x)=1-(\frac{b}{x})^a,~~~~~~~x \geq b >0,~a>0$$,  

I can derive its inverse  

$$\displaystyle F^{-1}(x)=\frac{b}{\sqrt[a]{1-x}}~~~~~~~0 \leq x \leq 1,~a>0$$,  

Then I could generate random variables from Uniform(0,1).  

I will simulate a sample number of 10000, $a=b=2$ as the exercise suggests.  
The pdf of the Pareto(a,b) distribution is  

$$f(x)=\displaystyle \frac{ab^a}{x^{a+1}},~~~~~~~x \geq b >0,~a>0$$ 


```{r}

n <- 10000
a <- 2
b <- 2
unifrv <- runif(n)
paretorv <- b/(1-unifrv)^(1/a)    # inverse transformation
hist(paretorv[paretorv>0 & paretorv<20], freq = FALSE, breaks = seq(0,20,0.5), main = "Histogram of the Pareto sample with the true density curve",xlab = "Sample value")    # graph the density histogram
# I found that F(20)=0.99, which is very close to 1. For the sake of the tidiness and better description for the feature of the histogram, I made a truncation on x=20, and only consider the variables between 0 and 20.
f <- function(x) {a*b^a/x^(a+1)}    # true pdf
curve(f, 2, 20, col = 2, lwd = 3, add = TRUE)    # add the true density curve
legend(12,0.6,"true density", col = 2, lwd = 3)    # add a legend

```

## Exercise 3.9
### Problem
The rescaled Epanechnikov kernel is a symmetric density function  

$$\displaystyle f_e(x)=\frac{3}{4}(1-x^2),~~~~~~~|x| \leq 1$$  

Devroye and Gyorfi give the following algorithm for simulation from this distribution. Generate iid $U_1,U_2,U_3 \sim$ Uniform(-1,1). If $|U_3|\geq|U_2|$ and $|U_3|\geq|U_1|$, deliver $U_2$; otherwise deliver |U_3|. Write a function to generate random variates from $f_e$, and construct the histogram density estimate of a large simulated random sample.

### Solution

Just do as the problem suggests. Consider a sample number of 10000.
```{r}
u1 <- runif(10000, min = -1, max = 1)    # consider a sample number of 10000
u2 <- runif(10000, min = -1, max = 1)
u3 <- runif(10000, min = -1, max = 1)
u <- ifelse((abs(u3)>abs(u2) & abs(u3)>abs(u1)), u2, u3)
hist(u, freq = FALSE, breaks = seq(-1,1,0.02), main = "Histogram with the true density curve", xlab = "Sample value")
f <- function(x) {3/4*(1-x^2)}
curve(f, -1, 1, col = 2, lwd = 3, add = TRUE)    # add the true density curve
legend(0.5,0.85,"true density", col = 2, lwd = 3, cex=0.6)    # add a legend

```

## Exercise 3.10
### Problem
Prove that the algorithm given in Exercise 3.9 generates variates from the density $f_e$

### Solution
Let $X_1=|U_1|, X_2=|U_2|, X_3=|U_3|$,then clearly there is $X_1,X_2,X_3 \sim$ Uniform(0,1).  

Let $X= \begin{cases}
X_2 & ~~X_3 \geq X_1~~and~~ X_3 \geq X_2 \\
X_3 & ~~otherwise \\
\end{cases}$  
Then, since $f_e(x)$ is symmetric, all I have to prove is that $X$ obeys the pdf  
$$f_{e'}(x)=2*\frac{3}{4}(1-x^2),~~~~~~~0 \leq x \leq 1$$  

Now, notice that the algorithm to generate $X$ can be rewritten as:  

1. Generate $X_1,X_2,X_3 \sim$ Uniform(0,1).  
2. Remove the largest value $X_{(3)}$  
3. Select one of the remaining two values with equal probability. Let $X$ be this value.  

For any $0 \leq x \leq 1$, consider the events:  
$A=\{$ only one of the $X_i \leq x$ $\}$  
$B=\{$ at least two of the $X_i \leq x$ $\}$,  
Then, it's easy to compute the cdf of $X$, $F_{e'}(x)$ as following:

\begin{align}
F_{e'}(x)&=P(X\leq x)\\
&=P(X \leq x,A)+P(X \leq x,B)\\
&=P(X \leq x~|~A)*P(A) + P(X \leq x~|~B)*P(B)\\
&=\frac{1}{2}*3x(1-x)^2 + 1*[3x^2(1-x) + x^3]\\
&=-\frac{1}{2} x^3 +\frac{3}{2}x,~~~~~~0 \leq x \leq 1
\end{align}  

Thus, the pdf of $X$ is 
$$ f_{e'}(x)=F'_{e'}(x)=2*\frac{3}{4}(1-x^2),~~~~~~~0 \leq x \leq 1 $$  

Thus, the algorithm given in Exercise 3.9 generates variates from the density $f_e. ~~~ \Box$ 


## Exercise 3.13
### Problem
It can be shown that the mixture in Exercise 3.12 has a Pareto distribution with cdf  
$$F(y)=1-\Big(\frac{\beta}{\beta+y}\Big)^r,~~~~~~~y\geq0$$  

(This is an alternative parameterization of the Pareto cdf given in Exercise
3.3.) Generate 1000 random observations from the mixture with $r=4$ and $\beta=2$. Compare the empirical and theoretical (Pareto) distributions by graphing the density histogram of the sample and superimposing the Pareto density curve.

### Solution
Just do as the problem suggests.  
When $r=4$ and $\beta=2$, the Pareto distribution has a pdf of  
$$f(y)=\frac{64}{(2+y)^5},~~~~~~~y \geq 0 $$

# Homework 3 (2020-10-13)

## Exercise 5.1
### Problem
Compute a Monte Carlo estimate of
$$\int_0^{\pi/3} sin~t~dt$$
and compare your estimate with the exact value of the integral.


### Solution

Use the simple Monte Carlo integration. 
$$X \sim Uniform(0,\pi/3),~~~g(X)=\pi sin(X)/3$$
The exact value is
$$\int_0^{\pi/3} sin~t~dt=cos(0)-cos(\pi/3)=0.5$$

```{r}
set.seed(3333)
monte_carlo_rep <- 100000
uniform_x <- runif(monte_carlo_rep,0,pi/3)
single_estimate <- sin(uniform_x)*pi/3
final_estimate <- mean(single_estimate)
final_estimate
#=0.5006204, very close to the exact value 0.5.
```

## Exercise 5.7
### Problem
Refer to Exercise 5.6. Use a Monte Carlo simulation to estimate $\theta$ by the antithetic variate approach and by the simple Monte Carlo method. Compute an empirical estimate of the percent reduction in variance using the antithetic variate. Compare the result with the theoretical value from Exercise 5.6

### Solution

$$\theta=\int_0^1 e^xdx$$
$$Var(e^U)=E(e^{2U})-(E(e^U))^2=\int_0^1 e^{2x}dx-(\int_0^1 e^{x}dx)^2=\frac{1}{2}(e^2-1)-(e-1)^2=0.2420$$
$$Cov(e^U,e^{1-U})=E(e^{U+1-U)})-E(e^U)E(e^{1-U})=e-\int_0^1e^xdx \int_0^1e^{1-x}dx=-0.2342$$
$$Var((e^U+e^{1-U})/2)=Var(e^U)/4+Var(e^{1-U})/4+Cov(e^U,e^{1-U})/2=0.0039$$

Thus, the theoretical value of percent reduction is $1-0.0039/0.2420=98.39\%$  

Next, we could compute an empirical estimate of the percent reduction in variance by the Monte Carlo simulation.
```{r}
set.seed(2222)
monte_carlo_r <- 100
var_reduc_store <- rep(0,monte_carlo_r)
for (i in 1:monte_carlo_r){
  u <- runif(10000)
  simple_mc <- exp(1)^u
  antithetic <- (exp(1)^u+exp(1)^(1-u))/2
  var_reduc_store[i] <- 1- var(antithetic) / var(simple_mc)
}
mean(var_reduc_store)
# empirical estimate of the percent reduction is 98.38%, very close to the theoretical value 98.39%.
```

## Exercise 5.11
### Problem
If $\hat{\theta}_1$ and $\hat{\theta}_2$ are unbiased estimators of $\theta$, and 
$\hat{\theta}_1$ and $\hat{\theta}_2$ are antithetic, we derived that $c^*=1/2$ is the optimal constant that minimizes the variance of $\hat{\theta}_c=c \hat{\theta}_1+(1-c)\hat{\theta}_2$. Derive $c^*$ for the general case. That is , if $\hat{\theta}_1$ and $\hat{\theta}_2$ are any two unbiased estimators of $\theta$, find the value $c^*$ that minimizes the variance of the estimator $\hat{\theta}_c=c \hat{\theta}_1+(1-c)\hat{\theta}_2$.  


### Solution

\begin{align}
Var(\hat{\theta}_c) &= Var(c \hat{\theta}_1+(1-c)\hat{\theta}_2)\\
&=c^2 Var(\hat{\theta}_1) + (1-c)^2 Var(\hat{\theta}_2) + 2c(1-c) Cov(\hat{\theta}_1,\hat{\theta}_2)\\
&=(Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2))c^2+(2Cov(\hat{\theta}_1,\hat{\theta}_2)-2Var(\hat{\theta}_2))c+Var(\hat{\theta}_2)\\
&=(Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2))(c+\frac{Cov(\hat{\theta}_1,\hat{\theta}_2)-Var(\hat{\theta}_2)}{Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2)})^2+K
\end{align}
,where K is the remaining item irrelevant to c.  

In addition, we know that $0 \leq c \leq 1$,  

Thus, to minimize the variance, $c*= \begin{cases}
0 & ~~~~ \frac{Var(\hat{\theta}_2)-Cov(\hat{\theta}_1,\hat{\theta}_2)}{Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2)} <0\\
\frac{Var(\hat{\theta}_2)-Cov(\hat{\theta}_1,\hat{\theta}_2)}{Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2)} &~~~~ 0 \leq \frac{Var(\hat{\theta}_2)-Cov(\hat{\theta}_1,\hat{\theta}_2)}{Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2)} \leq 1 \\
1 & ~~~~ \frac{Var(\hat{\theta}_2)-Cov(\hat{\theta}_1,\hat{\theta}_2)}{Var(\hat{\theta}_1)+Var(\hat{\theta}_2)-2Cov(\hat{\theta}_1,\hat{\theta}_2)} >1\\
\end{cases}$

$\Box$

# Homework 4 (2020-10-20)

## Exercise 5.13
### Problem
Find two importance functions $f_1$ and $f_2$ that are supported on $(1,\infty)$ and are 'close' to
$$g(x)=\frac{x^2}{\sqrt{2\pi}} e^{-x^2/2},~~~~x>1$$
Which of your two importance functions should produce the smaller variance in estimating
$$\int_1^{\infty} \frac{x^2}{\sqrt{2\pi}}e^{-x^2/2} dx$$
by importance sampling? Explain.

### Solution
Considering the properties of the integrand, I find two functions that are 'close' to the integrand and are supported on $(1,\infty)$. They are $e^{-x/2}$ and $e^{-(x-1)}$. To make them density functions, they need to be multiplied by a constant.

$$f_1(x)=\frac{\sqrt{e}}{2}e^{-x/2},~~~~x>1$$
$$f_2(x)=e^{-(x-1)},~~~~x>1$$


```{r}
set.seed(3333)
g <- function(x) x^2*exp(-x^2/2)/sqrt(2*pi)
f1 <- function(x) sqrt(exp(1))/2*exp(-x/2)
f2 <- function(x) exp(-(x-1))
plot(g,1,5,ylim=c(0,1),ylab='y')
par(new=TRUE)
plot(f1,1,5,xlab='',ylab='',main='',col='blue',ylim=c(0,1))
par(new=TRUE)
plot(f2,1,5,xlab='',ylab='',main='',col='red',ylim=c(0,1))
legend(4,0.9,c("g","f1","f2"), col = c('black','blue','red'),lwd = c(1,1,1))
```

From the figure, it seems that the most nearly constant ratio $g(x)/f(x)$ appears to be $f_2$. Thus, I might prefer $f_2$ for the smallest variance.

```{r}
set.seed(3333)
m <- 100000
se <- rep(0,2)
theta.hat <- rep(0,2)
g <- function(x) x^2*exp(-x^2/2)/sqrt(2*pi)
f1 <- function(x) sqrt(exp(1))/2*exp(-x/2)
f2 <- function(x) exp(-(x-1))

u1 <- runif(m,0,0.5)    # to confirm that all the x1>1
x1 <- -2*log(u1 * 2 / sqrt(exp(1)))    # f1, using inverse transform method
f1g <- g(x1)/f1(x1)
theta.hat[1] <- mean(f1g)
se[1] <- sd(f1g)

x2 <- rexp(m)+1
f2g <- g(x2)/f2(x2)
theta.hat[2] <- mean(f2g)
se[2] <- sd(f2g)

theta.hat
# 0.4014080 0.4002661, both are close to the real value.
se
# 0.302011 0.157805, f2 has smaller standard error, as I expected.
```


## Exercise 5.15
### Problem
Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.

### Solution

```{r}
set.seed(3333)
m <- 10000
g <- function(x) exp(-x - log(1+x^2))
f1 <- function(x) exp(-x)/(1-exp(-1/5))
f2 <- function(x) exp(-x)/(exp(-1/5)-exp(-2/5))
f3 <- function(x) exp(-x)/(exp(-2/5)-exp(-3/5))
f4 <- function(x) exp(-x)/(exp(-3/5)-exp(-4/5))
f5 <- function(x) exp(-x)/(exp(-4/5)-exp(-1))

u <- runif(m)
x1 <- -log(1-u*((1-exp(-1/5))))
x2 <- -log(exp(-1/5)-u*((exp(-1/5)-exp(-2/5))))
x3 <- -log(exp(-2/5)-u*((exp(-2/5)-exp(-3/5))))
x4 <- -log(exp(-3/5)-u*((exp(-3/5)-exp(-4/5))))
x5 <- -log(exp(-4/5)-u*((exp(-4/5)-exp(-1))))

fg1 <- g(x1)/f1(x1)
fg2 <- g(x2)/f2(x2)
fg3 <- g(x3)/f3(x3)
fg4 <- g(x4)/f4(x4)
fg5 <- g(x5)/f5(x5)

fg <- fg1+fg2+fg3+fg4+fg5

mean(fg)
# 0.5248477, very close to the result in Example 5.10

sd(fg)
# 0.01694816, much smaller than the result in Example 5.10

```


## Exercise 6.4
### Problem
Suppose that $X_1,...,X_n$ are a random sample from a from a lognormal distribution with unknown parameters. Construct a 95% confidence interval for the parameter $\mu$. Use a Monte Carlo method to obtain an empirical estimate of the confidence level.

### Solution
Set $n=100, m=100, \mu=5, \sigma=1$
```{r}
library(stats)
set.seed(3333)
n <- 100
m <- 100
l_bound <- rep(0,m)
u_bound <- rep(0,m)
for (i in 1:100) {
  x <- rlnorm(n,5,1)
  mu_hat <- sum(log(x))/n
  q <- qt(1-0.05/2,n-1)
  sigmasqu_hat <- sum((log(x)-mu_hat)^2)/n
  se_hat <- sigmasqu_hat/sqrt(n)
  l_bound[i] <- mu_hat - q*se_hat
  u_bound[i] <- mu_hat + q*se_hat
}
lb <- mean(l_bound)
ub <- mean(u_bound)
c(lb,ub)
# an empirical estimate of the confidence level is [4.808141, 5.199664], while the true value is 5.
```



## Exercise 6.5
### Problem
Suppose a 95% symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^2(2)$ data with sample size $n = 20$. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.)

### Solution

Random samples of $\chi^2(2)$ data with sample size $n = 20$ is non-normal, while the random samples in Example 6.4 is normal with mean=0 and sd=2.

```{r}
set.seed(3333)
n <- 20
m <- 10000
lb_non <- rep(0,m)
ub_non <- rep(0,m)
lb_nor <- rep(0,m)
ub_nor <- rep(0,m)
for (i in 1:m) {
  non_normal_x <- rchisq(n,2)
  lb_non[i] <- mean(non_normal_x) - sd(non_normal_x)*qt(1-0.05/2,n-1)/sqrt(n)
  ub_non[i] <- mean(non_normal_x) + sd(non_normal_x)*qt(1-0.05/2,n-1)/sqrt(n)
  normal_x <- rnorm(n,mean=0,sd=2)
  lb_nor[i] <- mean(normal_x) - sd(normal_x)*qt(1-0.05/2,n-1)/sqrt(n)
  ub_nor[i] <- mean(normal_x) + sd(normal_x)*qt(1-0.05/2,n-1)/sqrt(n)
}
cov_prob_non <- mean(lb_non<2 & ub_non>2)
cov_prob_nor <- mean(lb_nor<0 & ub_nor>0)
c(cov_prob_non,cov_prob_nor)
# The normal samples have a coverage probability of 94.9%, which is effective. However, the non-normal samples only have a coverage probability of 91.73%, which suggests that the probability that the confidence interval covers the mean is not necessarily equal to 0.95 for non-normal samples.
```

# Homework 5 (2020-10-27)

## Exercise 6.7
### Problem
Estimate the power of the skewness test of normality against symmetric Beta($\alpha,\alpha$) distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as t($\nu$)?

### Solution

```{r}
set.seed(3333)
sk <- function(x) {
  # skewness computation
  m2 <- mean((x-mean(x))^2)
  m3 <- mean((x-mean(x))^3)
  m3/(m2*sqrt(m2))
}

n <- 40
m <- 2000
alpha_test <- 0.1    # confidence level alpha
alpha <- c(seq(0,1,0.1),seq(1,10,0.5))    # parameter alpha for symmetric Beta distribution
N <- length(alpha)
powerrate <- rep(0,N)
critical_value <- qnorm(1-alpha_test/2, 0, sqrt((n-2)*6 / ((n+3)*(n+1))))

for (i in 1:N) {
  test_rej <- rep(0,m)
  for (j in 1:m) {
    x <- rbeta(n,alpha[i],alpha[i])
    test_rej[j] <- (critical_value <= abs(sk(x)))
  }
  powerrate[i] <- mean(test_rej)
}

plot(alpha,powerrate,xlab=bquote(alpha),type='b',ylim=c(0,1))
abline(h = alpha_test, lty = 3)
se <- sqrt(powerrate*(1-powerrate)/m)    # add standard errors
lines(alpha, powerrate+se, lty = 3)
lines(alpha, powerrate-se, lty = 3)

nu <- c(seq(0.1,1,0.1),seq(2,20,1))    # paramer nu for t distribution
N_t <- length(nu)
powerrate_t <- rep(0,N_t)

for (i in 1:N_t) {
  test_rej <- rep(0,m)
  for (j in 1:m) {
    x <- rt(n,nu[i])
    test_rej[j] <- (critical_value <= abs(sk(x)))
  }
  powerrate_t[i] <- mean(test_rej)
}

plot(nu,powerrate_t,xlab=bquote(nu),type='b',ylim=c(0,1))
abline(h = alpha_test, lty = 3)
se_t <- sqrt(powerrate_t*(1-powerrate_t)/m)    # add standard errors
lines(nu, powerrate_t+se_t, lty = 3)
lines(nu, powerrate_t-se_t, lty = 3)

# The result of heavy-tailed symmetric distribution (such as t-distribution) and light-tailed symmetric distribution (such as beta-distribution with alpha>1) are significantly different! Heavy-tailed symmetric distribution has higher power, while light-tailed symmetric distribution has very low power.
```

## Exercise 6.8
### Problem
Refer to Example 6.16. Repeat the simulation, but also compute the F test of equal variance, at significance level $\hat{\alpha}=0.055$. Compare the power of the Count Five test and F test for small, medium, and large sample sizes. (Recall that the F test is not applicable for non-normal distributions.)

### Solution
```{r}
set.seed(3333)

count5test <- function(x, y) {
  x_central <- x - mean(x)
  y_central <- y - mean(y)
  x_outlier <- sum(x_central > max(y_central)) + sum(x_central < min(y_central))
  y_outlier <- sum(y_central > max(x_central)) + sum(y_central < min(x_central))
  # return 1 (reject) or 0 (do not reject H0)
  as.integer(max(c(x_outlier,y_outlier)) > 5)
}

n_small <- 20
n_medium <- 80
n_large <- 200
# small, medium and large sample sizes

m <- 2000
sigma1 <- 1
sigma2 <- 1.5
# generate samples under H1 to estimate power

power_s_c5 <- mean(replicate(m, expr={
x <- rnorm(n_small, 0, sigma1)
y <- rnorm(n_small, 0, sigma2)
count5test(x, y)
}))

power_m_c5 <- mean(replicate(m, expr={
x <- rnorm(n_medium, 0, sigma1)
y <- rnorm(n_medium, 0, sigma2)
count5test(x, y)
}))

power_l_c5 <- mean(replicate(m, expr={
x <- rnorm(n_large, 0, sigma1)
y <- rnorm(n_large, 0, sigma2)
count5test(x, y)
}))

power_s_f <- mean(replicate(m, expr={
x <- rnorm(n_small, 0, sigma1)
y <- rnorm(n_small, 0, sigma2)
as.integer(var.test(x,y)$p.value < 0.055)
}))

power_m_f <- mean(replicate(m, expr={
x <- rnorm(n_medium, 0, sigma1)
y <- rnorm(n_medium, 0, sigma2)
as.integer(var.test(x,y)$p.value < 0.055)
}))

power_l_f <- mean(replicate(m, expr={
x <- rnorm(n_large, 0, sigma1)
y <- rnorm(n_large, 0, sigma2)
as.integer(var.test(x,y)$p.value < 0.055)
}))

c(power_s_c5, power_s_f)
# For small sample sizes, Count Five Test power=0.3115, F-Test power=0.4220
c(power_m_c5, power_m_f)
# For medium sample sizes, Count Five Test power=0.8060, F-Test power=0.9500
c(power_l_c5, power_l_f)
# For large sample sizes, Count Five Test power=0.9550, F-Test power=1
```

## Exercise 6.C
### Problem
Repeat Examples 6.8 and 6.10 for Mardia’s multivariate skewness test. Mardia proposed tests of multivariate normality based on multivariate generalizations of skewness and kurtosis. If X and Y are iid, the multivariate population skewness $\beta_{1,d}$ is defined by Mardia as
$$\beta_{1,d}=E[(X-\mu)^T \Sigma^{-1}(Y-\mu)]^3$$
Under normality, $\beta_{1,d}=0$. The multivariate skewness statistic is
$$b_{1,d}=\frac{1}{n^2} \sum_{i,j=1}^n [(X_i-\bar{X})^T \hat{\Sigma}^{-1}(X_j-\bar{X})]^3$$
where $\hat{\Sigma}$ is the maximum likelihood estimator of covariance. Large values of $b_{1,d}$ are significant. The asymptotic distribution of $nb_{1,d}$  is chisquared with $d(d+1)(d + 2)/6$ degrees of freedom.

### Solution
```{r}
set.seed(3333)
library(MASS)
mul_sk <- function(x) {
  # computes the Mardia multivariate sample skewness coeff.
  n <- nrow(x)
  sigma <- var(x)
  sigmainv <- solve(sigma)
  mu <- apply(x,2,mean)
  x_cen <- x-mu
  sk <- 0
  for (i in 1:n)
    for (j in 1:n)
      sk <- sk + (t(as.matrix(x_cen[i,])) %*% sigmainv %*% as.matrix((x_cen[j,])))^3
  sk/n^2
}

d <- 2    # We suppose the dimension is 2
n <- c(5, 10, 20, 30)    # sample sizes
cv <- qchisq(0.975,d*(d+1)*(d+2)/6)

# n is a vector of sample sizes
# we are doing length(n) different simulations
p.reject <- numeric(length(n))    # to store sim. results
m <- 100    # num. repl. each sim.  It should be 1000, but to shorten the vignettes creation time, I manually switch it to 100.
for (i in 1:length(n)) {
  sktests <- numeric(m)    # test decisions
  for (j in 1:m) {
    x <- mvrnorm(n[i],c(0,0),matrix(c(1,0,0,1),2,2))    # test decision is 1 (reject) or 0
    sktests[j] <- as.integer(n[i]*abs(mul_sk(x))/6 >= cv)
  }
  p.reject[i] <- mean(sktests)    # proportion rejected
}
p.reject
# when n=5,10,20,30, p.reject=0.222,0.146,0.114,0.107
# This is a repetition of Example 6.8 for multivariate case.

alpha <- .1
n <- 30
m <- 30    # It should be 100, but to shorten the vignettes creation time, I manually switch it to 30.
epsilon <- c(seq(0, .15, .05), seq(.2, 1, .2))
N <- length(epsilon)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qchisq(0.975,d*(d+1)*(d+2)/6)
for (j in 1:N) {    # for each epsilon
  e <- epsilon[j]
  sktests <- numeric(m)
  for (i in 1:m) {    # for each replicate
    x <- (1-e)*mvrnorm(n, c(0,0), matrix(c(1,0,0,1),2,2)) + e*mvrnorm(n, c(0,0), matrix(c(100,0,0,100),2,2))
    sktests[i] <- as.integer(n*abs(mul_sk(x))/6 >= cv)
  }
  pwr[j] <- mean(sktests)
}
# plot power vs epsilon
plot(epsilon, pwr, type = "b", xlab = bquote(epsilon), ylim = c(0,1))
abline(h = .1, lty = 3)
se <- sqrt(pwr * (1-pwr) / m)    # add standard errors
lines(epsilon, pwr+se, lty = 3)
lines(epsilon, pwr-se, lty = 3)

# This is a repetition of Example 6.10 for multivariate case.
```

## Discussion
### Problem
If we obtain the powers for two methods under a particular simulation setting with 10000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?  

1. What is the corresponding hypothesis test problem?  

2. What test should we use? Z-test, two-sample t -test, paired-t-test or McNemar test?  

3. What information is needed to test your hypothesis?

### Solution

1. H0: The powers of the methods are equal. H1: The powers of the methods are different.

2. Power is actually a random variable which obeys binomial distribution divided by n: B(n,p)/n, where n is the number of experiments (10000 in this case), and p denotes the probability that the method would reject the H0 in a single experiment.  

n=10000 is large enough. Thus, the normal approximation is reasonable. The nonparametric methods are also available. There are no pairwise relation. Thus, Z-test, two-sample t-test and McNemar test are practicable.

3. No other extra information is needed. For example, using the two-sample t-test, we can get the p-value < 0.05, which means the powers of the methods are different at 0.05 level.

# Homework 6 (2020-11-03)

## Exercise 7.1
### Problem

Compute a jackknife estimate of the bias and the standard error of the correlation statistic in Example 7.2.

### Solution

```{r}
set.seed(3333)
library(bootstrap)
law <- as.matrix(law)
corr <- cor(law[,1],law[,2])
n <- nrow(law)
jackknife_store <- rep(0,n)
for (i in 1:n) {
  jacksample <- law[-i,]
  jackknife_store[i] <- cor(jacksample[,1],jacksample[,2])
}
jackknife_bias <- (n-1)*(mean(jackknife_store)-corr)
jackknife_se <- (n-1)*sd(jackknife_store)/sqrt(n)
c(jackknife_bias, jackknife_se)
# Bias=-0.006473623, SE=0.1425186
```

## Exercise 7.5           
### Problem

Refer to Exercise 7.4. Compute 95% bootstrap confidence intervals for the mean time between failures $1/\lambda$ by the standard normal, basic, percentile, and BCa methods. Compare the intervals and explain why they may differ.

### Solution
```{r}
set.seed(3333)
library(boot)
aircondit <- as.matrix(aircondit)
boot.mean <- function(x,i) mean(x[i])
boot.obj <- boot(aircondit, statistic=boot.mean, R=2000)
print(boot.ci(boot.obj, type = c("norm","basic","perc","bca")))
```

## Exercise 7.8
### Problem

Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard error of $\hat{\theta}$

### Solution


```{r}
set.seed(3333)
library(bootstrap)
scor <- as.matrix(scor)
n <- nrow(scor)
lambda <- eigen(cov(scor))$values
theta <- lambda[1] / (lambda[1]+lambda[2]+lambda[3]+lambda[4]+lambda[5])
jackknife_theta <- rep(0,n)
for (i in 1:n) {
  jacksample <- scor[-i,]
  lambda_j <- eigen(cov(jacksample))$values
  jackknife_theta[i] <- lambda_j[1] / (lambda_j[1]+lambda_j[2]+lambda_j[3]+lambda_j[4]+lambda_j[5])
}
jackknife_bias <- (n-1)*(mean(jackknife_theta)-theta)
jackknife_se <- (n-1)*sd(jackknife_theta)/sqrt(n)
c(jackknife_bias,jackknife_se)
# Bias=0.001069139, SE=0.049552307
```


## Exercise 7.8
### Problem

In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Use leave-two-out cross validation to compare the models.

### Solution

```{r}
library(DAAG)
attach(ironslag)
n <- length(magnetic)
e1 <- numeric(n*(n-1)/2)
e2 <- numeric(n*(n-1)/2)
e3 <- numeric(n*(n-1)/2)
e4 <- numeric(n*(n-1)/2)
count <- 0
for (i in 1:(n-1))
  for (j in (i+1):n) {
    count <- count+1
    y <- magnetic[-c(i,j)]
    x <- chemical[-c(i,j)]
    
    P1 <- lm(y~x)
    y1_1 <- chemical[i]*P1$coef[2] + P1$coef[1]
    y1_2 <- chemical[j]*P1$coef[2] + P1$coef[1]
    e1[count] <- (magnetic[i]-y1_1)^2+(magnetic[j]-y1_2)^2
    
    P2 <- lm(y~x+I(x^2))
    y2_1 <- P2$coef[1] + P2$coef[2] * chemical[i] + P2$coef[3] * chemical[i]^2
    y2_2 <- P2$coef[1] + P2$coef[2] * chemical[j] + P2$coef[3] * chemical[j]^2
    e2[count] <- (magnetic[i]-y2_1)^2+(magnetic[j]-y2_2)^2
    
    P3 <- lm(log(y)~x)
    y3_1 <- exp(P3$coef[1] + P3$coef[2] * chemical[i])
    y3_2 <- exp(P3$coef[1] + P3$coef[2] * chemical[j])
    e3[count] <- (magnetic[i]-y3_1)^2+(magnetic[j]-y3_2)^2
    
    P4 <- lm(log(y)~log(x))
    y4_1 <- exp(P4$coef[1] + P4$coef[2] * log(chemical[i]))
    y4_2 <- exp(P4$coef[1] + P4$coef[2] * log(chemical[j]))
    e4[count] <- (magnetic[i]-y4_1)^2+(magnetic[j]-y4_2)^2
  }

c(mean(e1)/2,mean(e2)/2,mean(e3)/2,mean(e4)/2)
# 19.57227 17.87018 18.45491 20.46718
# According to the prediction error criterion, Model 2, the quadratic model, would again be the best fit for the data.
```

# Homework 7 (2020-11-10)

## Exercise 8.3
### Problem

The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.

### Solution

```{r}
# Case without Permutation:

set.seed(123)

count5test <- function(x, y) {
X <- x - mean(x)
Y <- y - mean(y)
outx <- sum(X > max(Y)) + sum(X < min(Y))
outy <- sum(Y > max(X)) + sum(Y < min(X))
return(as.integer(max(c(outx, outy)) > 5))
}

n1 <- 20
n2 <- 30
mu1 <- mu2 <- 0
sigma1 <- sigma2 <- 1
m <- 1000
alphahat <- mean(replicate(m, expr={
x <- rnorm(n1, mu1, sigma1)
y <- rnorm(n2, mu2, sigma2)
x <- x - mean(x) #centered by sample mean
y <- y - mean(y)
count5test(x, y)
}))
print(alphahat)

# 0.104, suggests that the “Count Five” criterion does not necessarily control Type I error at alpha <= 0.0625 when the sample sizes are unequal.

# Now we use Permutation Method to deal with the same data:

per_countfivetest <- function(z,B) {
  n <- length(z)
  rst <- rep(0,B)
  for (i in 1:B) {
    z <- sample(z)
    rst[i] <- count5test(z[1:(n/2)],z[-(1:(n/2))])
  }
  mean(rst)
}

alphahat2 <- mean(replicate(m, expr={
x <- rnorm(n1, mu1, sigma1)
y <- rnorm(n2, mu2, sigma2)
x <- x - mean(x) #centered by sample mean
y <- y - mean(y)
per_countfivetest(c(x,y),50)
}))
print(alphahat2)

# 0.06154, this is a good Type-I error, which is much closer to 0.0625, and suggests that this is an available permutation test for equal variance that applies when sample sizes are not necessarily equal.
```

## Discussion          
### Problem

Design experiments for evaluating the performance of the NN, energy and ball methods in various situations:

(1).Unequal variances and equal expectations.  

(2).Unequal variances and unequal expectations.  

(3).Non-normal distributions: t distribution with 1 df.  

(4).Non-normal distributions: mixture of two normal distributions.  

(5).Unbalanced samples.


### Solution
```{r eval=FALSE}
set.seed(333)
library(Ball)
library(energy)
library(boot)
library(RANN)

m <- 100
k <- 3
p <- 2
mu <- 0.2
R <- 99
n <- n1+n2
N <- c(n1,n2)
alpha <- 0.1
sample_size <- c(10,20,30,50,80,100)

Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}

eqdist.nn <- function(z,sizes,k){
boot.obj <- boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}

compare_1 <- function(sample_size) {
  n1 <- n2 <- sample_size
  n <- n1+n2
  N <- c(n1,n2)
  p.values <- matrix(NA,m,3)
  for(i in 1:m){
  x <- matrix(rnorm(n1*p,0,1.7),ncol=p);
  y <- cbind(rnorm(n2,0,1.7),rnorm(n2));
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,num.permutations=99,seed=i)$p.value
  }
  colMeans(p.values<alpha)
}

case1 <- matrix(0,nrow=6,ncol=3)
for (i in 1:6)
  case1[i,] <- compare_1(sample_size[i])

plot(x=sample_size, y=case1[,1], type='b', xlab='Sample size', ylab='Power', main='Unequal variances and equal expectations',col=1,lwd=2,xlim=c(5,105),ylim=c(0,1))
lines(x=sample_size, y=case1[,2], type="b", lwd=2, col=2)
lines(x=sample_size, y=case1[,3], type="b", lwd=2, col=3)
legend(x=5,y=1,legend=c('NN','Energy','Ball'),lwd=2,col=c(1,2,3))

# Unequal variances and equal expectations

# To save the time of create vignette, we don't run the remaining three cases.
compare_2 <- function(sample_size) {
  n1 <- n2 <- sample_size
  n <- n1+n2
  N <- c(n1,n2)
  p.values <- matrix(NA,m,3)
  for(i in 1:m){
  x <- matrix(rnorm(n1*p,0,1.7),ncol=p);
  y <- cbind(rnorm(n2,0,1.7),rnorm(n2,mean=mu));
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,num.permutations=99,seed=i)$p.value
  }
  colMeans(p.values<alpha)
}

case2 <- matrix(0,nrow=6,ncol=3)
for (i in 1:6)
  case2[i,] <- compare_2(sample_size[i])

plot(x=sample_size, y=case2[,1], type='b', xlab='Sample size', ylab='Power', main='Unequal variances and unequal expectations',col=1,lwd=2,xlim=c(5,105),ylim=c(0,1))
lines(x=sample_size, y=case2[,2], type="b", lwd=2, col=2)
lines(x=sample_size, y=case2[,3], type="b", lwd=2, col=3)
legend(x=70,y=0.4,legend=c('NN','Energy','Ball'),lwd=2,col=c(1,2,3))


# Unequal variances and unequal expectations.

compare_3 <- function(sample_size) {
  n1 <- n2 <- sample_size
  n <- n1+n2
  N <- c(n1,n2)
  p.values <- matrix(NA,m,3)
  for(i in 1:m){
  x <- matrix(rt(n1*p,1),ncol=p);
  y <- cbind(rt(n2,1),rt(n2,100));
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,num.permutations=99,seed=i)$p.value
  }
  colMeans(p.values<alpha)
}

case3 <- matrix(0,nrow=6,ncol=3)
for (i in 1:6)
  case3[i,] <- compare_3(sample_size[i])

plot(x=sample_size, y=case3[,1], type='b', xlab='Sample size', ylab='Power', main=' t-distribution',col=1,lwd=2,xlim=c(5,105),ylim=c(0,1))
lines(x=sample_size, y=case3[,2], type="b", lwd=2, col=2)
lines(x=sample_size, y=case3[,3], type="b", lwd=2, col=3)
legend(x=5,y=1,legend=c('NN','Energy','Ball'),lwd=2,col=c(1,2,3))

# Non-normal distributions: t distribution with 1 df.

compare_4 <- function(sample_size) {
  n1 <- n2 <- sample_size
  n <- n1+n2
  N <- c(n1,n2)
  p.values <- matrix(NA,m,3)
  for(i in 1:m){
  x <- matrix(rnorm(n1*p,(sample(10)<3)*1,1),ncol=p);
  y <- cbind(rnorm(n2,(sample(10)<3)*1,1),rnorm(n2,(sample(10)>=3)*1,1));
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,num.permutations=99,seed=i)$p.value
  }
  colMeans(p.values<alpha)
}

case4 <- matrix(0,nrow=6,ncol=3)
for (i in 1:6)
  case4[i,] <- compare_4(sample_size[i])

plot(x=sample_size, y=case4[,1], type='b', xlab='Sample size', ylab='Power', main='mixture normal distribution',col=1,lwd=2,xlim=c(5,105),ylim=c(0,1))
lines(x=sample_size, y=case4[,2], type="b", lwd=2, col=2)
lines(x=sample_size, y=case4[,3], type="b", lwd=2, col=3)
legend(x=5,y=1,legend=c('NN','Energy','Ball'),lwd=2,col=c(1,2,3))

# Non-normal distributions: mixture of two normal distributions.

compare_5 <- function(sample_size) {
  n1 <- n2 <- sample_size
  n <- n1+n2
  N <- c(n1,n2)
  p.values <- matrix(NA,m,3)
  for(i in 1:m){
  x <- matrix(rnorm(n1*(p+3),0,1.7),ncol=p+3);
  y <- cbind(rnorm(n2,0,1.7),rnorm(n2),rnorm(n2),rnorm(n2),rnorm(n2));
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,num.permutations=99,seed=i)$p.value
  }
  colMeans(p.values<alpha)
}

case5 <- matrix(0,nrow=6,ncol=3)
for (i in 1:6)
  case5[i,] <- compare_5(sample_size[i])

plot(x=sample_size, y=case5[,1], type='b', xlab='Sample size', ylab='Power', main='Unbalanced samples with the Case 1',col=1,lwd=2,xlim=c(5,105),ylim=c(0,1))
lines(x=sample_size, y=case5[,2], type="b", lwd=2, col=2)
lines(x=sample_size, y=case5[,3], type="b", lwd=2, col=3)
legend(x=70,y=0.4,legend=c('NN','Energy','Ball'),lwd=2,col=c(1,2,3),cex=0.8)

# Unbalanced samples with the Case 1. (1:4)

# From the comparison, we can find that Ball test is usually the most powerful method of these three. When dealing with mixture normal distribution, Energy test behaves better.
```

# Homework 8 (2020-11-17)

## Exercise 9.4
### Problem

Implement a random walk Metropolis sampler for generating the standard Laplace distribution. For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.

### Solution

The standard Laplace distribution has density
$$
f(x)=\frac{1}{2}e^{-|x|},~~~~x \in R
$$
Thus,
$$
r(x_t,y)=f(Y)/f(X_t)=e^{-|y|+|x_t|}
$$

```{r}
set.seed(3333)
rw.Metro.Laplace <- function(sigma,x0,N) {
  u <- runif(N)
  x <- rep(0,N)
  x[1] <- x0
  k <- 0
  for (i in 2:N) {
    y <- rnorm(1, mean=x[i-1], sd=sigma)
    if (u[i] <= exp(abs(x[i-1])-abs(y)))
      x[i] <- y else {
        x[i] <- x[i-1]
        k <- k+1
      }
  }
  return(list(x=x,k=k))
}

sigma <- c(0.05,0.2,0.5,1,2,10)
x0 <- 20
N <- 2000

rw1 <- rw.Metro.Laplace(sigma[1],x0,N)
rw2 <- rw.Metro.Laplace(sigma[2],x0,N)
rw3 <- rw.Metro.Laplace(sigma[3],x0,N)
rw4 <- rw.Metro.Laplace(sigma[4],x0,N)
rw5 <- rw.Metro.Laplace(sigma[5],x0,N)
rw6 <- rw.Metro.Laplace(sigma[6],x0,N)
print(cbind(sigma=sigma, acc_rate=1-c(rw1$k,rw2$k,rw3$k,rw4$k,rw5$k,rw6$k)/N))

par(mfrow=c(2,3))
plot(rw1$x,type='l',xlab='sigma=0.05',ylab='X')
plot(rw2$x,type='l',xlab='sigma=0.2',ylab='X')
plot(rw3$x,type='l',xlab='sigma=0.5',ylab='X')
plot(rw4$x,type='l',xlab='sigma=1',ylab='X')
plot(rw5$x,type='l',xlab='sigma=2',ylab='X')
plot(rw6$x,type='l',xlab='sigma=10',ylab='X')
```

## Gelman-Rubin method for Exercise 9.4
### Problem
For Exercise 9.4, use the Gelman-Rubin method to monitor convergence of the chain, and run the chain until it converges approximately to the target distribution according to $\hat{R}<1.2$

### Solution

```{r eval=FALSE}
Gelman.Rubin <- function(psi) {
# psi[i,j] is the statistic psi(X[i,1:j])
# for chain in i-th row of X
psi <- as.matrix(psi)
n <- ncol(psi)
k <- nrow(psi)
psi.means <- rowMeans(psi) #row means
B <- n * var(psi.means) #between variance est.
psi.w <- apply(psi, 1, "var") #within variances
W <- mean(psi.w) #within est.
v.hat <- W*(n-1)/n + (B/n) #upper variance est.
r.hat <- v.hat / W #G-R statistic
return(r.hat)
}

k <- 4    # four chains
x0 <- c(-10,-5,5,10)    # overdispersed initial values
N <- 10000    # length of chains
b <- 200    # burn-in length

par(mfrow=c(2,2))

X <- matrix(nrow=k,ncol=N)
for (i in 1:k)
  X[i,] <- rw.Metro.Laplace(0.2,x0[i],N)$x
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
rhat <- rep(0, N)
for (j in (1000+1):N)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(1000+1):N], type="l", xlab="sigma=0.2", ylab="R_hat")
abline(h=1.2, lty=2)

X <- matrix(nrow=k,ncol=N)
for (i in 1:k)
  X[i,] <- rw.Metro.Laplace(1,x0[i],N)$x
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
rhat <- rep(0, N)
for (j in (500+1):N)
rhat[j] <- Gelman.Rubin(psi[,1:j])
x2 <- min(which(rhat>0 & rhat<1.2))
plot(rhat[(500+1):N], type="l", xlab="sigma=1", ylab="R_hat")
abline(h=1.2, lty=2)

X <- matrix(nrow=k,ncol=N)
for (i in 1:k)
  X[i,] <- rw.Metro.Laplace(4,x0[i],N)$x
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
rhat <- rep(0, N)
for (j in (b+1):N)
rhat[j] <- Gelman.Rubin(psi[,1:j])
x3 <- min(which(rhat>0 & rhat<1.2))
plot(rhat[(b+1):N], type="l", xlab="sigma=4", ylab="R_hat")
abline(h=1.2, lty=2)

X <- matrix(nrow=k,ncol=N)
for (i in 1:k)
  X[i,] <- rw.Metro.Laplace(16,x0[i],N)$x
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
rhat <- rep(0, N)
for (j in (b+1):N)
rhat[j] <- Gelman.Rubin(psi[,1:j])
x4 <- min(which(rhat>0 & rhat<1.2))
plot(rhat[(b+1):N], type="l", xlab="sigma=16", ylab="R_hat")
abline(h=1.2, lty=2)

c(x2,x3,x4)
```
From the result, we know that from our simulation:  

1. When $\sigma=0.5$, the chain don't converge in the first $N=10000$ iterations based on the criteria $\hat{R}<1.2$.  

2. When $\sigma=1$, the chain converges at $N=5611$ iteration based on the criteria $\hat{R}<1.2$.  

3. When $\sigma=4$, the chain converges at $N=525$ iteration based on the criteria $\hat{R}<1.2$.  

4. When $\sigma=16$, the chain converges at $N=2860$ iteration based on the criteria $\hat{R}<1.2$.  


## Exercise 11.4
### Problem

Find the intersection points $A(k)$ in $(0,\sqrt{k})$ of the curves
$$
S_{k-1}(a)=P\left(t(k-1)>\sqrt{\frac{a^{2}(k-1)}{k-a^{2}}}\right)
$$
and
$$
S_{k}(a)=P\left(t(k)>\sqrt{\frac{a^{2} k}{k+1-a^{2}}}\right)
$$
for $k=4:25,100,500,1000$, where t(k) is a Student t random variable with k degrees of freedom.

### Solution

```{r}
S <- function(k,a) {
  tmp <- sqrt(a^2*k/(k+1-a^2))
  pt(tmp, df=k)
}
k_store <- 4:25

result <- numeric(length(k_store)+3)
count <- 0

for (k in k_store) {
  count <- count+1
  target <- function(a) {
    S(k,a)-S(k-1,a)
  }
  out <- uniroot(target,  lower = 0.001, upper = sqrt(k)-0.1)
  result[count] <- out$root
}

target_100 <- function(a) {
    S(100,a)-S(99,a)
  }
out <- uniroot(target_100,  lower = 0.001, upper = sqrt(100)-4)    # To avoid meeting upper bound
result[23] <- out$root

target_500 <- function(a) {
    S(500,a)-S(499,a)
  }
out <- uniroot(target_500,  lower = 0.001, upper = sqrt(500)-20)    # To avoid meeting upper bound
result[24] <- out$root

target_1000 <- function(a) {
    S(1000,a)-S(999,a)
  }
out <- uniroot(target_1000,  lower = 0.001, upper = sqrt(1000)-25)    # To avoid meeting upper bound
result[25] <- out$root

cbind(k=c(k_store,100,500,1000),result)
```

# Homework 9 (2020-11-24)

## A-B-O blood type problem
### Problem

Let the three alleles be A, B and O.  

(Table omitted)  

Observed data:
A-type: $n_{A \cdot }=444$  

B-type: $n_{B \cdot }=132$  

O-type: $n_{OO}=361$  

AB-type: $n_{AB}=63$  


1. Use EM algorithm to solve MLE of $p$ and $q$. (consider missing data $n_{AA}$ and $n_{BB}$) 
2. Record the values of $p$ and $q$ that maximize the conditional likelihood in each EM steps, calculate the corresponding log-maximum likelihood values (for observed data), are they increasing?

### Solution

Observed data likelihood:
$$
L(p,q|n_{A\cdot},n_{B\cdot},n_{OO},n_{AB})=(p^2+2p(1-p-q))^{n_{A\cdot}}(q^2+2q(1-p-q))^{n_{B\cdot}}((1-p-q)^2)^{n_{OO}}(2pq)^{n_{AB}}
$$

Complete data likelihood:
$$
L(p,q|n_{AA},n_{BB},n_{OO},n_{AO},n_{BO},n_{AB})=(p^2)^{n_{AA}}(q^2)^{n_{BB}}((1-p-q)^2)^{n_{OO}}(2p(1-p-q))^{n_{AO}}(2q(1-p-q))^{n_{BO}}(2pq)^{n_{AB}}
$$
$$
L(p,q|n_{A\cdot},n_{B\cdot},n_{OO},n_{AB},n_{AA},n_{BB})=(p^2)^{n_{AA}}(q^2)^{n_{BB}}((1-p-q)^2)^{n_{OO}}(2p(1-p-q))^{n_{A\cdot}-n_{AA}}(2q(1-p-q))^{n_{B\cdot}-n_{BB}}(2pq)^{n_{AB}}
$$

$$
l(p,q|n_{A\cdot},n_{B\cdot},n_{OO},n_{AB},n_{AA},n_{BB}) = 2n_{OO}\log (1-p-q) + n_{AB} \log (pq) + n_{A\cdot}\log (p(1-p-q)) + n_{B\cdot}\log (q(1-p-q)) + n_{AA}\log (p/(1-p-q)) + n_{BB}\log (q/(1-p-q)) 
$$
E-Step:
$$
\begin{aligned}
&E_{\hat{p}_0,\hat{q}_0}[l(p,q|n_{A\cdot},n_{B\cdot},n_{OO},n_{AB},n_{AA},n_{BB})|n_{A\cdot},n_{B\cdot},n_{OO},n_{AB}]\\
&= 2n_{OO}\log (1-p-q) + n_{AB} \log (pq) + n_{A\cdot}\log (p(1-p-q)) + n_{B\cdot}\log (q(1-p-q))\\
&+ \frac{\hat{p}_0^2}{\hat{p}_0^2+2 \hat{p}_0(1-\hat{p}_0-\hat{q}_0)} n_{A\cdot}\log (p/(1-p-q)) + \frac{\hat{q}_0^2}{\hat{q}_0^2+2 \hat{q}_0(1-\hat{p}_0-\hat{q}_0)} n_{B\cdot}\log (q/(1-p-q))
\end{aligned}
$$

M-Step:
$$
\hat{p}_1=\frac{1}{2n}(2n_{A\cdot}\frac{\hat{p}_0^2}{\hat{p}_0^2+2 \hat{p}_0(1-\hat{p}_0-\hat{q}_0)}+n_{A\cdot}\frac{2 \hat{p}_0(1-\hat{p}_0-\hat{q}_0)}{\hat{p}_0^2+2 \hat{p}_0(1-\hat{p}_0-\hat{q}_0)}+n_{AB})
$$
$$
\hat{q}_1=\frac{1}{2n}(2n_{B\cdot}\frac{\hat{q}_0^2}{\hat{q}_0^2+2 \hat{q}_0(1-\hat{p}_0-\hat{q}_0)}+n_{B\cdot}\frac{2 \hat{q}_0(1-\hat{p}_0-\hat{q}_0)}{\hat{q}_0^2+2 \hat{p}_0(1-\hat{p}_0-\hat{q}_0)}+n_{AB})
$$

```{r}
na <- 444
nb <- 132
noo <- 361
nab <- 63
n <- na+nb+noo+nab
p <- rep(0,10)
q <- rep(0,10)
condlike <- rep(0,10)
p[1] <- 0.5    # Initial value
q[1] <- 0.2    # Initial value
for (i in 1:9) {
  x1 <- p[i]^2/(p[i]^2+2*p[i]*(1-p[i]-q[i]))
  x2 <- q[i]^2/(q[i]^2+2*q[i]*(1-p[i]-q[i]))
  r <- 1-p[i]-q[i]
  condlike[i] <- 2*noo*log(r) + nab*log(p[i]*q[i]) + na*log(p[i]*r) + nb*log(q[i]*r) + x1*na*log(p[i]/r) + x2*nb*log(q[i]/r)
  p[i+1] <- (2*na*x1+na*(1-x1)+nab)/(2*n)
  q[i+1] <- (2*nb*x2+nb*(1-x2)+nab)/(2*n)
  r <- 1-p[i+1]-q[i+1]
}
r <- 1-p[10]-q[10]
condlike[10] <- 2*noo*log(r) + nab*log(p[10]*q[10]) + na*log(p[10]*r) + nb*log(q[10]*r) + x1*na*log(p[10]/r) + x2*nb*log(q[10]/r)

data.frame(p=p,q=q,conditional_log_likelihood=condlike)
```
From the result, we could find that the corresponding log-maximum likelihood  values are increasing. The parameters converge after 9 iterations. The estimated $\hat{p}=0.2976407,~~\hat{q}=0.1027063$


## Exercises 3 (P204)
### Problem
Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list:

formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)

### Solution
```{r}
attach(mtcars)
formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)

# loops
models_1 <- list()
for (i in 1:4)
  models_1[[i]] <- lm(formulas[[i]])
models_1

# lapply
models_2 <- list()
models_2 <- lapply(formulas, function(x) lm(x))
models_2
```

## Exercises 3 (P213)
### Problem
The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.

trials <- replicate(
100,
t.test(rpois(10, 10), rpois(7, 10)),
simplify = FALSE
)

Extra challenge: get rid of the anonymous function by using [[ directly.

### Solution
```{r}
trials <- replicate(
100,
t.test(rpois(10, 10), rpois(7, 10)),
simplify = FALSE
)
sapply(trials, (function(x) x[['p.value']]))
sapply(trials, '[[', 'p.value')    # extra challenge
```

## Exercises 6 (P214)
### Problem
Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?

### Solution
```{r}
lapply_1 <- function(X, FUN, FUN.VALUE) {
  return(Map(function(x) vapply(x,FUN,FUN.VALUE),X))
}
list_comb <- list(cars,mtcars,faithful)
lapply_1(list_comb, mean, numeric(1))
```

# Homework 10 (2020-12-01)


### Problem

1.Write an Rcpp function for Exercise 9.4.  

2.Compare the corresponding generated random numbers with those by the R function you wrote before using the function "qqplot".  

3.Compare the computation time of the two functions with the function "microbenchmark".  

4.Comments your results.

## Solution

```{r eval=FALSE}
# Rcpp function for Exercise 9.4 (rwC.cpp)

#include <Rcpp.h>
using namespace Rcpp;
// [[Rcpp::export]]
NumericVector rwC (double sigma, double x0, int N) {
    NumericVector u = runif(N);
    NumericVector x(N);
    x[0] = x0;
    for (int i=1; i <= N-1; i++) {
        NumericVector y = rnorm(1,x[i-1],sigma);
        if (u[i] <= exp(abs(x[i-1])-abs(y[0]))) {
            x[i] = y[0];
        }
        if (u[i] > exp(abs(x[i-1])-abs(y[0]))) {
            x[i] = x[i-1];
        }
    }
    return(x);
}
```

```{r}
# R function for Exercise 9.4 (my homework)

rw.Metro.Laplace <- function(sigma,x0,N) {
  u <- runif(N)
  x <- rep(0,N)
  x[1] <- x0
  k <- 0
  for (i in 2:N) {
    y <- rnorm(1, mean=x[i-1], sd=sigma)
    if (u[i] <= exp(abs(x[i-1])-abs(y)))
      x[i] <- y else {
        x[i] <- x[i-1]
        k <- k+1
      }
  }
  return(list(x=x,k=k))
}
```

```{r}
library(Rcpp)
sourceCpp("rwC.cpp")
sigma <- 2
x0 <- 5
N <- 2000
qqplot(rwC(sigma,x0,N), rw.Metro.Laplace(sigma,x0,N)$x)
abline(a=0,b=1,col='red')
```

The corresponding generated random numbers could be assumed same, because the Q-Q plot of these two data mostly scatters near the diagonal line.

```{r}
library(microbenchmark)
ts <- microbenchmark(rwC=rwC(sigma,x0,N), rwR=rw.Metro.Laplace(sigma,x0,N)$x)
summary(ts)[,c(1,3,5,6)]
```

It's clear that Rcpp function takes much shorter time than R function. Thus, Rcpp can tremendously increase the efficiency.

